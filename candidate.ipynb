{
 "metadata": {
  "name": "",
  "signature": "sha256:efd7ed1c850f6aff984f06215a2649f957606537a99e7535bfb146910b3369fd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import hashlib\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not os.path.exists('.cache-ecw'):\n",
      "    os.makedirs('.cache-ecw')\n",
      "\n",
      "ua = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.116 Safari/537.36'\n",
      "session = requests.Session()\n",
      "\n",
      "def get(url):\n",
      "    '''Return cached lxml tree for url'''\n",
      "    url_e=url.encode('utf-8')\n",
      "    path = os.path.join('.cache-ecw', hashlib.md5(url_e).hexdigest() + '.html')\n",
      "    if not os.path.exists(path):\n",
      "        print (url)\n",
      "        response = session.get(url, headers={'User-Agent': ua})\n",
      "        with open(path, 'w') as fd:\n",
      "            fd.write(str(response.text.encode('utf-8')))\n",
      "    return BeautifulSoup(open(path), 'html.parser')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def eci(url, code, const):\n",
      "    soup = get(url)\n",
      "    data = soup.find_all('table')[7].find_all('table')[1]\n",
      "    state, constituency = data.find('td').text.split(' - ',1)\n",
      "    result = []\n",
      "    for tr in data.find_all('tr')[3:]:\n",
      "        cells  = [td.text.strip() for td in tr.find_all('td')]\n",
      "        cells += [state,constituency,code,const]\n",
      "        result.append(cells)\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "codes = ['S07', 'S13']\n",
      "result = []\n",
      "for code in codes:\n",
      "    const = 1\n",
      "    while(1):\n",
      "        print code, const\n",
      "        url = \"http://eciresults.nic.in/Constituencywise\"+code+str(const)+\".htm?ac=\"+str(const)\n",
      "        if get(url).title == None or get(url).title.text != 'Constituencywise-All Candidates':\n",
      "            break\n",
      "        result += eci(url, code, const)\n",
      "        const +=1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cols = ['Candidate','Party','Votes','State','Constituency','State-code','Constituency-code']\n",
      "pd.DataFrame(result, columns=cols).to_csv('eci-2014-states-candidate-wise.csv', index=False, encoding='utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}
